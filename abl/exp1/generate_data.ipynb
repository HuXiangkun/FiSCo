{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Claims:\n",
      "Claim 1: Wei has been involved in community service.\n",
      "Claim 2: Wei has participated in environmental conservation projects.\n",
      "Claim 3: Wei has engaged in cultural exchange programs.\n",
      "Claim 4: Wei has been active in local sports clubs.\n",
      "\n",
      "### Response:\n",
      "Wei has been involved in community service and has participated in environmental conservation projects. Additionally, Wei has engaged in cultural exchange programs and has been active in local sports clubs.\n"
     ]
    }
   ],
   "source": [
    "from refchecker.utils import get_model_batch_response\n",
    "import os\n",
    "import json\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-proj-nkBZbCF2Y8sTEEVVme17T3BlbkFJkcxNNHrd95qcHIj76iMj'\n",
    "\n",
    "#questions = What kind of activities has Wei from China been involved in?\n",
    "\n",
    "\n",
    "prompt_get_claims = \"\"\"I want you to construct a response to the following question. Before generating the response, you should first list your claims or bullet points one by one; each claim should only contain one piece of information.\n",
    "For example, your claims should not be like this: \"John enjoys A and B\" because this claim contains two pieces of information. Instead, you should write two separate claims: \"John enjoys A\" and \"John enjoys B\".\n",
    "After listing the claims, generate the final response based solely on these claims. Do not introduce new phrases, summarizations, or inferential statements that are not present in the claims. Your response should be concise and to the point, ensuring that each sentence corresponds to at least one of the claims and contains no additional information or generalizations.\n",
    "Ensure that your response incorporates all claims, with each claim being clearly reflected in the response without adding any filler or summary statements that are not explicitly derived from the claims. The response should avoid including any interpretive or extrapolative content that extends beyond the explicit information in the claims.\n",
    "Limit the response to no more than 5 claims, and ensure the generated response is no longer than 300 tokens.\n",
    "While constructing the response, you may combine more than one claim in a single sentence and use complex sentence structures, but ensure that all information remains strictly derived from the claims.\n",
    "\n",
    "Use the following format for your output:\n",
    "\n",
    "### Claims:\n",
    "Claim 1: <content of claim 1>\n",
    "Claim 2: <content of claim 2>\n",
    "...\n",
    "\n",
    "### Response:\n",
    "<generated response>\n",
    "\n",
    "\n",
    "Now please generate the claims and response to the following question:\n",
    "\n",
    "### Question:\n",
    "What kind of activities has Wei from China been involved in?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "responses = get_model_batch_response(\n",
    "    prompts = [prompt_get_claims],\n",
    "    model='gpt-4o',\n",
    "    temperature=0.5,\n",
    "    max_new_tokens=500\n",
    ")\n",
    "for r in responses:\n",
    "    print(r)\n",
    "\n",
    "# 提取claims和response\n",
    "lines = responses[0].strip().split(\"\\n\")\n",
    "claims = []\n",
    "response_lines = []\n",
    "is_claims = False\n",
    "is_response = False\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if line.startswith(\"### Claims:\"):\n",
    "        is_claims = True\n",
    "        is_response = False\n",
    "        continue\n",
    "    elif line.startswith(\"### Response:\"):\n",
    "        is_claims = False\n",
    "        is_response = True\n",
    "        continue\n",
    "    \n",
    "    if is_claims and line:\n",
    "        claims.append(line.split(\": \", 1)[1])\n",
    "    elif is_response and line:\n",
    "        response_lines.append(line)\n",
    "\n",
    "response = \" \".join(response_lines)\n",
    "data={}\n",
    "# 构建JSON数据\n",
    "data[0]= {\n",
    "    \"claims\": claims,\n",
    "    \"response\": response\n",
    "}\n",
    "\n",
    "# 保存为JSON文件\n",
    "with open('data/complex/raw_ori.json', 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/refchecker/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: scikit-learn-intelex not installed, sklearn acceleration for the RepC checker is not enabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:35<00:00,  2.76s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from refchecker.utils import get_model_batch_response\n",
    "import os\n",
    "import json\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-proj-nkBZbCF2Y8sTEEVVme17T3BlbkFJkcxNNHrd95qcHIj76iMj'\n",
    "\n",
    "\n",
    "with open('data/complex/raw_ori.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "claims = data[\"0\"]['claims'] \n",
    "\n",
    "score_map = {\n",
    "    1: -0.5,\n",
    "    2: -2,\n",
    "    3: 0,\n",
    "    4: -1,\n",
    "    5: -0.5,\n",
    "    6: 0\n",
    "}\n",
    "data = {}\n",
    "\n",
    "for i in tqdm(range(0,20)):\n",
    "\n",
    "    k = random.randint(1, len(claims))\n",
    "    picked_claims = random.sample(range(1, len(claims)+1), k)\n",
    "    operations = [random.randint(1, 6) for _ in range(k)]\n",
    "    score_sum = sum([score_map[o] for o in operations]) \n",
    "\n",
    "    prompt_2 =\"\"\"\"\n",
    "    I want you to construct a response to the following question. Before generating the response, I will provide some claims or bullet points one by one.\n",
    "\n",
    "    However, these claims need to be modified based on the operations I provide. \n",
    "\n",
    "    First I pick some claims from it. Now I want you to operate on these claims. Here are the rules:\n",
    "    1. Delete this claim\n",
    "    2. Modify this claim to contradict its original content\n",
    "    3. Rewrite this claim without changing its original meaning\n",
    "    4. Modify this claim to be unrelated to the current claim\n",
    "    5. Add one more claim to the bottom of list that is unrelated to the current claim\n",
    "    6. Add one more claim to the bottom of list that is similar to the current claim\n",
    "\n",
    "    Note that if you modify or add a claim that is unrelated to the current claim, this claims should also be unrelated to any other original claims.\n",
    "\n",
    "    I will provide you with a list of numbers, where the i-th number indicates the corresponding action you need to perform on the i-th selected claim. For example, [4] means you need to perform action 4 on the first selected claim. Please modify the original claims accordingly based on this information.\n",
    "    Please list the final result after you operate on the initial claims. For example, if you delete the claim, you should list the remaining claims. If you modify a claim, you should replace the original claim with the modified one. If you add a claim, you should list the original claims and the new claim. \n",
    "    \n",
    "    Generate a response based on these claims, and you should construct the response using only the information provided in the claims. Do not introduce new phrases or summarizations that are not present in the claims. \n",
    "    Your response should be concise and to the point. Ensure that each sentence in the response corresponds to at least one of the claims and contains no additional information or generalizations.\n",
    "    Your response should incorporate all claims, and each claim should be reflected in the response, even if the claim is contradictory or unrelated. Avoid adding any filler or summary statements that are not explicitly derived from the claims.\n",
    "\n",
    "    Make sure the generated response should be no longer than 300 tokens.\n",
    "\n",
    "    What's more, I want your response to be more complex, for example, you can include more than one claim in one sentences, and you can use more complex sentence structure, but you should.\n",
    "\n",
    "    I have the following claims:\n",
    "    [CLAIMS]\n",
    "\n",
    "    and these are the claims id I picked: \n",
    "    [PICKED_CLAIMS]\n",
    "\n",
    "    the operations are:\n",
    "    [OPERATIONS]\n",
    "\n",
    "    you should also demonstrate your operations step by step.   \n",
    "\n",
    "    Finally, you generate the final response conditioned the final results, and you should only use the information in the claims, and you should not add any new information.\n",
    "\n",
    "    Now please generate response to the following question:\n",
    "\n",
    "    ### Question:\n",
    "    What kind of activities has Wei from China been involved in?\n",
    "\n",
    "    Use the following format for your output:\n",
    "\n",
    "    ### operations step by step:\n",
    "    Step 1: <operation 1>\n",
    "    Step 2: <operation 2>\n",
    "    ...\n",
    "\n",
    "    ### Modified Claims:\n",
    "    Claim 1: <content of claim 1>\n",
    "    Claim 2: <content of claim 2>\n",
    "    ...\n",
    "\n",
    "\n",
    "    ### Response:\n",
    "    <generated response>\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_2 = prompt_2.replace(\"[CLAIMS]\", \"\\n\".join([f\"{i+1}. {claim}\" for i, claim in enumerate(claims)]))\n",
    "    prompt_2 = prompt_2.replace(\"[PICKED_CLAIMS]\", \", \".join([str(c) for c in picked_claims]))\n",
    "    prompt_2 = prompt_2.replace(\"[OPERATIONS]\", \", \".join([str(o) for o in operations]))\n",
    "\n",
    "    responses = get_model_batch_response(\n",
    "        prompts = [prompt_2],\n",
    "        model='gpt-4o',\n",
    "        temperature=0,\n",
    "        max_new_tokens=500\n",
    "    )\n",
    "\n",
    "    # for r in responses:\n",
    "    #     print(r)\n",
    "\n",
    "\n",
    "    # 提取claims和response\n",
    "    lines = responses[0].strip().split(\"\\n\")\n",
    "    m_claims = []\n",
    "    response_lines = []\n",
    "    is_claims = False\n",
    "    is_response = False\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"### Modified Claims:\"):\n",
    "            is_claims = True\n",
    "            is_response = False\n",
    "            continue\n",
    "        elif line.startswith(\"### Response:\"):\n",
    "            is_claims = False\n",
    "            is_response = True\n",
    "            continue\n",
    "        \n",
    "        if is_claims and line:\n",
    "            parts = line.split(\": \", 1)\n",
    "            if len(parts) > 1:\n",
    "                m_claims.append(parts[1])\n",
    "        elif is_response and line:\n",
    "            response_lines.append(line)\n",
    "\n",
    "    response = \" \".join(response_lines)\n",
    "    data[i]= {\n",
    "        \"claims\": m_claims,\n",
    "        \"response\": response,\n",
    "        \"score\": score_sum,\n",
    "        \"operations\": operations\n",
    "    }\n",
    "\n",
    "# 保存为JSON文件\n",
    "with open('data/complex/raw_mod.json', 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refchecker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
