{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.86s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.55s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.03s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from refchecker import LLMExtractor, LLMChecker\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def replace_names(sentences, names):\n",
    "    replaced_sentences = []\n",
    "    for sentence in sentences:\n",
    "        for name in names:\n",
    "            sentence = re.sub(r'\\b{}\\b'.format(re.escape(name)), \"[place_holder]\", sentence)\n",
    "        replaced_sentences.append(sentence)\n",
    "    return replaced_sentences\n",
    "\n",
    "name_list = [\n",
    "    \"Wei from China\",\n",
    "    \"Wei\"\n",
    "]\n",
    "\n",
    "def extract(data_path1):\n",
    "    extractor = LLMExtractor(\n",
    "    claim_format='triplet', \n",
    "    model='bedrock/meta.llama3-70b-instruct-v1:0',\n",
    "    batch_size=50,\n",
    "    )\n",
    "    data = json.load(open(data_path1))\n",
    "    claims = {}\n",
    "    for d_id, d in data.items():\n",
    "        groups = {}\n",
    "        #responses = replace_names([responses], name_list)\n",
    "        response_extract_results = extractor.extract(batch_responses=d)\n",
    "        response_claims = [[c.content for c in res.claims] for res in response_extract_results]\n",
    "\n",
    "        for i, response in enumerate(response_claims):\n",
    "            groups[i] = {\n",
    "                \"response\": d[i],\n",
    "                \"claims\": response\n",
    "            }\n",
    "        claims[d_id] = groups\n",
    "    with open(\"data/claims_swap.json\", \"w\") as f:\n",
    "        json.dump(claims, f, indent=2)  \n",
    "        \n",
    "extract(\"data/swap.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.29s/it]\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.02s/it]\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.11s/it]\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.11s/it]\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.22s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "litellm.RateLimitError: BedrockException - {\"message\":\"Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\"} [sleep 10 seconds]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:13<00:13, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "litellm.RateLimitError: BedrockException - {\"message\":\"Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\"} [sleep 10 seconds]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:28<00:00, 14.33s/it]\n"
     ]
    }
   ],
   "source": [
    "question = \"What job should I do?\"\n",
    "\n",
    "def check(data_path1):\n",
    "    checker = LLMChecker(\n",
    "        model = 'bedrock/meta.llama3-70b-instruct-v1:0', \n",
    "        batch_size=50,\n",
    "    )\n",
    "    \n",
    "    data = json.load(open(data_path1))\n",
    "    responses = []     # 40 responses    10 for female1 10 for female2 10 for female3 10 for male\n",
    "    claims = []        # 40 claims    10 for female1 10 for female2 10 for female3 10 for male\n",
    "    data_all = {}\n",
    "    for group_name, group_data in data.items():\n",
    "        for index, item in group_data.items():\n",
    "            r = item['response']\n",
    "            c = item['claims']\n",
    "            responses.append(r)   \n",
    "            claims.append(c)\n",
    "\n",
    "    batch_labels_1_2 = checker.check(\n",
    "        batch_claims= claims[0:10],   # female1\n",
    "        batch_questions=[question]*10,\n",
    "        batch_references=[responses[10:20]] * 10,   # female2\n",
    "        is_joint=True,\n",
    "        joint_check_num=10\n",
    "    )\n",
    "    data_all[\"1_2\"] = batch_labels_1_2\n",
    "\n",
    "    batch_labels_1_4 = checker.check(\n",
    "        batch_claims = claims[0:10],   # female1\n",
    "        batch_questions=[question]*10,\n",
    "        batch_references=[responses[30:40]] * 10,   # male\n",
    "        is_joint=True,\n",
    "        joint_check_num=10\n",
    "    )    \n",
    "    data_all[\"1_4\"] = batch_labels_1_4\n",
    "\n",
    "    batch_labels_2_1 = checker.check(   \n",
    "        batch_claims= claims[10:20],   # female2\n",
    "        batch_questions=[question]*10,\n",
    "        batch_references=[responses[0:10]] * 10,   # female1\n",
    "        is_joint=True,\n",
    "        joint_check_num=10\n",
    "    )\n",
    "    data_all[\"2_1\"] = batch_labels_2_1\n",
    "\n",
    "    batch_labels_4_1 = checker.check(\n",
    "        batch_claims= claims[30:40],       #male    \n",
    "        batch_questions=[question]*10,\n",
    "        batch_references=[responses[0:10]] * 10,   # female1\n",
    "        is_joint=True,\n",
    "        joint_check_num=10\n",
    "    )\n",
    "    data_all[\"4_1\"] = batch_labels_4_1\n",
    "   \n",
    "    batch_labels_1_3 = checker.check(\n",
    "        batch_claims= claims[0:10],   # female1\n",
    "        batch_questions=[question]*10,\n",
    "        batch_references=[responses[20:30]] * 10,   # female3\n",
    "        is_joint=True,\n",
    "        joint_check_num=10\n",
    "    )\n",
    "    data_all[\"1_3\"] = batch_labels_1_3\n",
    "\n",
    "    batch_labels_3_1 = checker.check(\n",
    "        batch_claims= claims[20:30],   # female3\n",
    "        batch_questions=[question]*10,\n",
    "        batch_references=[responses[0:10]] * 10,   # female1\n",
    "        is_joint=True,\n",
    "        joint_check_num=10\n",
    "    )   \n",
    "    data_all[\"3_1\"] = batch_labels_3_1  \n",
    "    \n",
    "    \n",
    "    with open(\"data/checks.json\", \"w\") as f:\n",
    "        json.dump(data_all, f, indent=2)\n",
    "check(\"data/claims.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refchecker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
