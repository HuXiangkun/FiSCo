{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.86s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.55s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.03s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from refchecker import LLMExtractor, LLMChecker\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def replace_names(sentences, names):\n",
    "    replaced_sentences = []\n",
    "    for sentence in sentences:\n",
    "        for name in names:\n",
    "            sentence = re.sub(r'\\b{}\\b'.format(re.escape(name)), \"[place_holder]\", sentence)\n",
    "        replaced_sentences.append(sentence)\n",
    "    return replaced_sentences\n",
    "\n",
    "name_list = [\n",
    "    \"Wei from China\",\n",
    "    \"Wei\"\n",
    "]\n",
    "\n",
    "def extract(data_path1):\n",
    "    extractor = LLMExtractor(\n",
    "    claim_format='triplet', \n",
    "    model='bedrock/meta.llama3-70b-instruct-v1:0',\n",
    "    batch_size=50,\n",
    "    )\n",
    "    data = json.load(open(data_path1))\n",
    "    claims = {}\n",
    "    for d_id, d in data.items():\n",
    "        groups = {}\n",
    "        #responses = replace_names([responses], name_list)\n",
    "        response_extract_results = extractor.extract(batch_responses=d)\n",
    "        response_claims = [[c.content for c in res.claims] for res in response_extract_results]\n",
    "\n",
    "        for i, response in enumerate(response_claims):\n",
    "            groups[i] = {\n",
    "                \"response\": d[i],\n",
    "                \"claims\": response\n",
    "            }\n",
    "        claims[d_id] = groups\n",
    "    with open(\"data/claims_swap.json\", \"w\") as f:\n",
    "        json.dump(claims, f, indent=2)  \n",
    "        \n",
    "extract(\"data/swap.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Entailment', 'Entailment', 'Entailment', 'Entailment', 'Entailment']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 84\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/checks.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     83\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(data_all, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m \u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/claims.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 33\u001b[0m, in \u001b[0;36mcheck\u001b[0;34m(data_path1)\u001b[0m\n\u001b[1;32m     25\u001b[0m batch_labels_1_2 \u001b[38;5;241m=\u001b[39m checker\u001b[38;5;241m.\u001b[39mcheck(\n\u001b[1;32m     26\u001b[0m     batch_claims\u001b[38;5;241m=\u001b[39m claims[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m],   \u001b[38;5;66;03m# female1\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     batch_questions\u001b[38;5;241m=\u001b[39m[question]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     joint_check_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch_labels_1_2[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     34\u001b[0m data_all[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1_2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch_labels_1_2\n\u001b[1;32m     36\u001b[0m batch_labels_1_4 \u001b[38;5;241m=\u001b[39m checker\u001b[38;5;241m.\u001b[39mcheck(\n\u001b[1;32m     37\u001b[0m     batch_claims \u001b[38;5;241m=\u001b[39m claims[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m],   \u001b[38;5;66;03m# female1\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     batch_questions\u001b[38;5;241m=\u001b[39m[question]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     joint_check_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     42\u001b[0m )    \n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from refchecker import LLMExtractor, LLMChecker\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "question = \"What job should I do?\"\n",
    "\n",
    "def check(data_path1):\n",
    "    checker = LLMChecker(\n",
    "        model = 'bedrock/meta.llama3-70b-instruct-v1:0', \n",
    "        batch_size=50,\n",
    "    )\n",
    "    \n",
    "    data = json.load(open(data_path1))\n",
    "    responses = []     # 40 responses    10 for female1 10 for female2 10 for female3 10 for male\n",
    "    claims = []        # 40 claims    10 for female1 10 for female2 10 for female3 10 for male\n",
    "    data_all = {}\n",
    "    for group_name, group_data in data.items():\n",
    "        for index, item in group_data.items():\n",
    "            r = item['response']\n",
    "            c = item['claims']\n",
    "            responses.append(r)   \n",
    "            claims.append(c)\n",
    "\n",
    "    batch_labels_1_2 = checker.check(\n",
    "        batch_claims= claims[0:10],   # female1\n",
    "        batch_questions=[question]*10,\n",
    "        batch_references=[responses[10:20]] * 10,   # female2\n",
    "        is_joint=True,\n",
    "        joint_check_num=10\n",
    "    )\n",
    "    print(batch_labels_1_2[0])\n",
    "    assert 0\n",
    "    data_all[\"1_2\"] = batch_labels_1_2\n",
    "\n",
    "    batch_labels_1_4 = checker.check(\n",
    "        batch_claims = claims[0:10],   # female1\n",
    "        batch_questions=[question]*10,\n",
    "        batch_references=[responses[30:40]] * 10,   # male\n",
    "        is_joint=True,\n",
    "        joint_check_num=10\n",
    "    )    \n",
    "    data_all[\"1_4\"] = batch_labels_1_4\n",
    "\n",
    "    batch_labels_2_1 = checker.check(   \n",
    "        batch_claims= claims[10:20],   # female2\n",
    "        batch_questions=[question]*10,\n",
    "        batch_references=[responses[0:10]] * 10,   # female1\n",
    "        is_joint=True,\n",
    "        joint_check_num=10\n",
    "    )\n",
    "    data_all[\"2_1\"] = batch_labels_2_1\n",
    "\n",
    "    batch_labels_4_1 = checker.check(\n",
    "        batch_claims= claims[30:40],       #male    \n",
    "        batch_questions=[question]*10,\n",
    "        batch_references=[responses[0:10]] * 10,   # female1\n",
    "        is_joint=True,\n",
    "        joint_check_num=10\n",
    "    )\n",
    "    data_all[\"4_1\"] = batch_labels_4_1\n",
    "   \n",
    "    batch_labels_1_3 = checker.check(\n",
    "        batch_claims= claims[0:10],   # female1\n",
    "        batch_questions=[question]*10,\n",
    "        batch_references=[responses[20:30]] * 10,   # female3\n",
    "        is_joint=True,\n",
    "        joint_check_num=10\n",
    "    )\n",
    "    data_all[\"1_3\"] = batch_labels_1_3\n",
    "\n",
    "    batch_labels_3_1 = checker.check(\n",
    "        batch_claims= claims[20:30],   # female3\n",
    "        batch_questions=[question]*10,\n",
    "        batch_references=[responses[0:10]] * 10,   # female1\n",
    "        is_joint=True,\n",
    "        joint_check_num=10\n",
    "    )   \n",
    "    data_all[\"3_1\"] = batch_labels_3_1  \n",
    "    \n",
    "    \n",
    "    with open(\"data/checks.json\", \"w\") as f:\n",
    "        json.dump(data_all, f, indent=2)\n",
    "check(\"data/claims.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refchecker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
