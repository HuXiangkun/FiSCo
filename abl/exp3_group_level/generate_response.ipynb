{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_f = \"\"\"\n",
    "A young man who has just graduated from university is passionate about life, works actively, and is preparing to get engaged to his girlfriend\"\"\"\n",
    "\n",
    "persona_m = \"\"\"\n",
    "A middle-aged man who has been working for over 20 years is experienced, composed in his actions, and has a son in high school.\"\"\"\n",
    "\n",
    "import json\n",
    "questions_path = \"data/gender/gender.json\"\n",
    "\n",
    "with open(questions_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "questions = []\n",
    "\n",
    "for i, item in data.items():\n",
    "    questions.append(item[\"questions\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from refchecker.utils import get_model_batch_response\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-proj-nkBZbCF2Y8sTEEVVme17T3BlbkFJkcxNNHrd95qcHIj76iMj'\n",
    "\n",
    "ori_prompt = \"\"\"\n",
    "We are conducting some experiments and need your help generating data. \n",
    "I will give you a question, and you need to generate 10 responses for this question. \n",
    "I will provide you with a user persona. When answering questions, you need to imagine the subject of the question as this persona. Your responses should be based on the information I provide about this character.\n",
    "The user persona is just a preliminary set of information provided to you. You are free to imagine additional details about this person based on the persona.\n",
    "Your responses should have diversity but remember your responses needs to align with the persona. \n",
    "Your response should be coherent and relevant to the question. And each response should be more than 5 sentences.\n",
    "\n",
    "You should give me your responses in the following format. You just need to put your responses in them and you shouldn't add any additional information:\n",
    "Avoid using names in your responses.\n",
    "### Responses\n",
    "1. [response1]\n",
    "2. [response2]\n",
    "3. [response3]\n",
    "4. [response4]\n",
    "5. [response5]\n",
    "6. [response6]\n",
    "7. [response7]\n",
    "8. [response8]\n",
    "9. [response9]\n",
    "10. [response10]\n",
    "\n",
    "Now please generate responses for the following question:\n",
    "[question]\n",
    "\n",
    "And here is the user persona:\n",
    "[persona]\n",
    "\n",
    "\"\"\"\n",
    "overall_data = []\n",
    "for questions in questions:\n",
    "    q_prompt = ori_prompt.replace(\"[question]\", questions)\n",
    "\n",
    "    prompt_f = q_prompt.replace(\"[persona]\", persona_f) \n",
    "    prompt_m = q_prompt.replace(\"[persona]\", persona_m)\n",
    "    responses1 = get_model_batch_response(\n",
    "        prompts = [prompt_f],\n",
    "        model='gpt-4o',\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=2000,\n",
    "    )\n",
    "    responses2 = get_model_batch_response(\n",
    "        prompts = [prompt_f],\n",
    "        model='gpt-4o',\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=2000,\n",
    "    )\n",
    "    responses3 = get_model_batch_response(\n",
    "        prompts = [prompt_m],\n",
    "        model='gpt-4o',\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=2000,\n",
    "    )\n",
    "    input_text1 = responses1[0]\n",
    "    response_pattern = r\"\\d+\\.\\s(.*?)(?=\\d+\\.\\s|$)\"\n",
    "\n",
    "    raw_data = input_text1\n",
    "\n",
    "    # Use re.findall to extract the 10 responses\n",
    "    processed_1 = re.findall(response_pattern, input_text1, re.DOTALL)\n",
    "\n",
    "    input_text2 = responses2[0]\n",
    "    processed_2 = re.findall(response_pattern, input_text2, re.DOTALL)\n",
    "\n",
    "    input_text3 = responses3[0]\n",
    "    processed_3 = re.findall(response_pattern, input_text3, re.DOTALL)\n",
    "    \n",
    "\n",
    "    data = {}\n",
    "    data['questions'] = questions\n",
    "    data['female1'] = processed_1\n",
    "    data['female2'] = processed_2\n",
    "    data['male1'] = processed_3 \n",
    "    data['raw'] = raw_data  \n",
    "\n",
    "    overall_data.append(data)\n",
    "\n",
    "data_path = './data/age/age.json'\n",
    "with open(data_path, 'w') as outfile:   \n",
    "    json.dump(overall_data, outfile, indent=4)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refchecker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
