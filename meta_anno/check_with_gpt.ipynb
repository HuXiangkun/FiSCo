{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Scores between text1 and text2:\n",
      "8.5\n",
      "\n",
      "### Explanation:\n",
      "Both texts provide a detailed, step-by-step guide on how to prepare for an important presentation, with significant overlap in the steps mentioned. Both texts emphasize understanding the audience, defining the objective, creating an outline, designing visual aids, and practicing the presentation. \n",
      "\n",
      "However, there are some differences:\n",
      "- Text2 includes steps like \"Research and gather materials\" and \"Anticipate questions,\" which are not explicitly mentioned in Text1.\n",
      "- Text1 includes steps like \"Get feedback\" and \"Rehearse in the actual presentation space,\" which are not explicitly mentioned in Text2.\n",
      "- Text2 also emphasizes staying calm and confident during the presentation, which is implied but not explicitly stated in Text1.\n",
      "\n",
      "Despite these differences, the core structure and intent of both texts are very similar, hence the high similarity score.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m response1 \u001b[38;5;241m=\u001b[39m responses[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(response1)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# 定义提取分数的正则表达式\u001b[39;00m\n\u001b[1;32m     57\u001b[0m pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m### Scores between text1 and text2:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)\u001b[39m\u001b[38;5;124m'\u001b[39m, re\u001b[38;5;241m.\u001b[39mDOTALL)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from refchecker.utils import get_model_batch_response\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# 设置API Key\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-proj-nkBZbCF2Y8sTEEVVme17T3BlbkFJkcxNNHrd95qcHIj76iMj'\n",
    "\n",
    "result = []\n",
    "\n",
    "# 模板\n",
    "prompt_template = \"\"\" I would like you to help me measure the semantic similarity between two pieces of text. \n",
    "I will provide you with two texts: text1 and text2. \n",
    "You need to return two score between 0 and 10, with a higher score indicating a greater similarity between the two texts. \n",
    "\n",
    "Use the following format for your output:\n",
    "\n",
    "### Scores between text1 and text2:\n",
    "[score]\n",
    "\n",
    "Now please give your assessment of the semantic similarity between the following texts:\n",
    "\n",
    "### text1:\n",
    "[text1]\n",
    "\n",
    "### text2:\n",
    "[text2]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 加载数据\n",
    "data_path = 'data/300/raw.json'\n",
    "with open(data_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "    reference = d['reference']  \n",
    "    text1 = d['text1']\n",
    "    text2 = d['text2']\n",
    "\n",
    "    # 生成第一个 prompt，替换文本\n",
    "    prompt1 = prompt_template.replace('[text1]', reference).replace('[text2]', text1)\n",
    "\n",
    "    # 获取第一个文本对的响应\n",
    "    responses = get_model_batch_response(\n",
    "        prompts=[prompt1],\n",
    "        model='gpt-4o',\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=500\n",
    "    )\n",
    "    response1 = responses[0]\n",
    "    print(response1)\n",
    "    assert 0\n",
    "\n",
    "    # 定义提取分数的正则表达式\n",
    "    pattern = re.compile(r'### Scores between text1 and text2:\\s*(\\d+)', re.DOTALL)\n",
    "\n",
    "    # 提取第一个分数\n",
    "    score1_match = pattern.search(response1)\n",
    "    score1 = float(score1_match.group(1)) if score1_match else None\n",
    "\n",
    "    # 生成第二个 prompt，替换文本\n",
    "    prompt2 = prompt_template.replace('[text1]', reference).replace('[text2]', text2)\n",
    "\n",
    "    # 获取第二个文本对的响应\n",
    "    responses = get_model_batch_response(\n",
    "        prompts=[prompt2],\n",
    "        model='gpt-4o',\n",
    "        temperature=0,\n",
    "        max_new_tokens=500\n",
    "    )\n",
    "    response2 = responses[0]\n",
    "\n",
    "    # 提取第二个分数\n",
    "    score2_match = pattern.search(response2)\n",
    "    score2 = float(score2_match.group(1)) if score2_match else None\n",
    "\n",
    "    # 输出提取的分数\n",
    "    print(f\"Scores for pair {i+1}: {score1}, {score2}\")\n",
    "    # 将结果存储到列表中\n",
    "    result.append([score1, score2])\n",
    " \n",
    "# 保存结果到json文件\n",
    "with open('data/300/gpt_score.json', 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('data/300/gpt_score.json', 'r') as f:\n",
    "    gpt_data = json.load(f)\n",
    "\n",
    "with open('data/300/raw.json', 'r') as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "correct = 0\n",
    "sum = 80\n",
    "for i, d in enumerate(raw_data):\n",
    "    d['gpt_score1'] = gpt_data[i][0]\n",
    "    d['gpt_score2'] = gpt_data[i][1]\n",
    "\n",
    "    \n",
    "\n",
    "    if d['gpt_score1'] > d['gpt_score2']:\n",
    "        d['gpt_label'] = 0\n",
    "    elif d['gpt_score1'] < d['gpt_score2']:\n",
    "        d['gpt_label'] = 1\n",
    "    else:\n",
    "        d['gpt_label'] = 2  # equal\n",
    "    \n",
    "    if d['gt_labels'] == d['gpt_label']:\n",
    "        correct += 1\n",
    "\n",
    "print(f'Accuracy: {correct/sum}')   \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refchecker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
