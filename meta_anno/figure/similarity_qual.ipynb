{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-Gram Similarity: 0.07142857142857144\n",
      "Bag-of-Words Similarity: 0.5\n",
      "TF-IDF Similarity: 0.3360969272762575\n",
      "Word Mover's Distance Similarity: 0.6216586985153256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Similarity: 0.9510157704353333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name princeton-nlp/sup-simcse-bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence-BERT Similarity: 0.6023814678192139\n",
      "SimCSE Similarity: 0.8354148864746094\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim.downloader as api\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# Define the sentences\n",
    "sentence1 = \"\"\"\n",
    "The software engineer is planning to enhance her skills by pursuing a master’s degree in computer science\n",
    "\"\"\"\n",
    "sentence2 = \"\"\"\n",
    "The mechanical engineer is eager to improve his qualifications by obtaining a master’s degree in engineering management.\n",
    "\"\"\"\n",
    "# Load pre-trained Word2Vec model\n",
    "w2v_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# 1. N-Gram Similarity\n",
    "def n_gram_similarity(s1, s2, n=3):\n",
    "    vectorizer = CountVectorizer(ngram_range=(n, n))\n",
    "    X = vectorizer.fit_transform([s1, s2])\n",
    "    return cosine_similarity(X[0:1], X[1:2])[0][0]\n",
    "\n",
    "# 2. Bag-of-Words (BoW) Similarity\n",
    "def bow_similarity(s1, s2):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform([s1, s2])\n",
    "    return cosine_similarity(X[0:1], X[1:2])[0][0]\n",
    "\n",
    "# 3. TF-IDF Similarity\n",
    "def tfidf_similarity(s1, s2):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform([s1, s2])\n",
    "    return cosine_similarity(X[0:1], X[1:2])[0][0]\n",
    "\n",
    "# 4. Word Mover's Distance (WMD)\n",
    "def wmd_similarity(s1, s2):\n",
    "    s1_tokens = [word for word in s1.lower().split() if word in w2v_model.key_to_index]\n",
    "    s2_tokens = [word for word in s2.lower().split() if word in w2v_model.key_to_index]\n",
    "    \n",
    "    if not s1_tokens or not s2_tokens:\n",
    "        return 0  # Return 0 if either sentence has no valid tokens\n",
    "\n",
    "    wmd_distance = w2v_model.wmdistance(s1_tokens, s2_tokens)\n",
    "    similarity = 1 / (1 + wmd_distance)  # Convert distance to similarity\n",
    "    return similarity\n",
    "\n",
    "# 5. BERTScore Similarity\n",
    "def bertscore_similarity(s1, s2):\n",
    "    from bert_score import score\n",
    "    _, _, F1 = score([s1], [s2], lang='en', verbose=False)\n",
    "    return F1[0].item()\n",
    "\n",
    "# 6. Sentence-BERT Similarity\n",
    "def sentence_bert_similarity(s1, s2):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings1 = model.encode(s1, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(s2, convert_to_tensor=True)\n",
    "    cosine_score = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    return cosine_score.item()\n",
    "\n",
    "# 7. SimCSE Similarity\n",
    "def simcse_similarity(s1, s2):\n",
    "    model = SentenceTransformer('princeton-nlp/sup-simcse-bert-base-uncased')  # Using a SimCSE model\n",
    "    embeddings1 = model.encode(s1, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(s2, convert_to_tensor=True)\n",
    "    cosine_score = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    return cosine_score.item()\n",
    "\n",
    "# Calculate similarities\n",
    "n_gram_sim = n_gram_similarity(sentence1, sentence2)\n",
    "print(f\"N-Gram Similarity: {n_gram_sim}\")\n",
    "bow_sim = bow_similarity(sentence1, sentence2)\n",
    "print(f\"Bag-of-Words Similarity: {bow_sim}\")\n",
    "tfidf_sim = tfidf_similarity(sentence1, sentence2)\n",
    "print(f\"TF-IDF Similarity: {tfidf_sim}\")\n",
    "wmd_sim = wmd_similarity(sentence1, sentence2)\n",
    "print(f\"Word Mover's Distance Similarity: {wmd_sim}\")\n",
    "bertscore_sim = bertscore_similarity(sentence1, sentence2)\n",
    "print(f\"BERTScore Similarity: {bertscore_sim}\")\n",
    "sentence_bert_sim = sentence_bert_similarity(sentence1, sentence2)\n",
    "print(f\"Sentence-BERT Similarity: {sentence_bert_sim}\")\n",
    "simcse_sim = simcse_similarity(sentence1, sentence2)\n",
    "print(f\"SimCSE Similarity: {simcse_sim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['The software engineer', 'is', 'planning'], ['The software engineer', 'planning to', 'enhance her skills'], ['The software engineer', 'enhance her skills by', 'pursuing a master’s degree in computer science'], ['The software engineer', 'pursuing', 'a master’s degree in computer science'], ['a master’s degree in computer science', 'in', 'computer science'], ['The software engineer', 'has skills', 'her skills']], [['The mechanical engineer', 'is', 'eager'], ['The mechanical engineer', 'wants to', 'improve his qualifications'], ['The mechanical engineer', 'wants to improve his qualifications by', 'obtaining a master’s degree'], ['The master’s degree', 'is in', 'engineering management'], ['The mechanical engineer', 'wants to obtain', 'a master’s degree in engineering management']]]\n",
      "6\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5\n",
      "[[['Entailment', 'Neutral'], ['Entailment', 'Neutral'], ['Entailment', 'Neutral'], ['Entailment', 'Neutral'], ['Entailment', 'Neutral'], ['Entailment', 'Neutral']], [['Neutral', 'Entailment'], ['Neutral', 'Entailment'], ['Neutral', 'Entailment'], ['Neutral', 'Entailment'], ['Neutral', 'Entailment']]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from refchecker import LLMExtractor, LLMChecker\n",
    "\n",
    "extractor = LLMExtractor(\n",
    "    claim_format='triplet', \n",
    "    model='bedrock/meta.llama3-70b-instruct-v1:0',\n",
    "    batch_size=50,\n",
    "    )\n",
    "\n",
    "response_extract_results = extractor.extract(\n",
    "            batch_responses=[sentence1, sentence2]\n",
    "        )\n",
    "response_claims = [[c.content for c in res.claims] for res in response_extract_results]\n",
    "print(response_claims)\n",
    "\n",
    "checker = LLMChecker(\n",
    "        model = 'bedrock/meta.llama3-70b-instruct-v1:0', \n",
    "        batch_size=50\n",
    ")\n",
    "\n",
    "question = \"\"\"\n",
    "Describe a job.\n",
    "\"\"\"\n",
    "print(len(response_claims[0]))\n",
    "print(len(response_claims[1]))  \n",
    "batch_labels = checker.check(\n",
    "            batch_claims=response_claims,\n",
    "            batch_questions=[question] * 2,\n",
    "            batch_references=[[sentence1,sentence2]] * 2,\n",
    "            is_joint=True,\n",
    "            joint_check_num=1\n",
    "            \n",
    "        )\n",
    "\n",
    "print(len(batch_labels[0]))\n",
    "print(len(batch_labels[1])) \n",
    "print(batch_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refchecker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
